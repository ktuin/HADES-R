{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# to set the path for importing HADES modules\n",
    "import sys\n",
    "sys.path.append(\"../source/\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import LatLongUTMconversion\n",
    "from hades_input import hades_input\n",
    "from hades_location import hades_location\n",
    "import hades_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridgecrest example to demonstrate how HADES works\n",
    "\n",
    "HADES works via the principle of inter-event distance estimation.\n",
    "\n",
    "\n",
    "[insert image here]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The data used for this tutorial is the _Ridgecrest 2019_ afterschock sequence after the Mw 6.4 earthquake, measured at two stations: ***WBS*** and ***WMF***, at a distance of () km and () km. The data is taken from: [_REFERENCE_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we load our data\n",
    "data_path = 'data/'                            \n",
    "input_file = 'inputs/ridgecrest_gji.dat'       # This contains the event times and arrival time picks\n",
    "station_file = 'inputs/stations_ridge.txt'     # This contains the station locations\n",
    "\n",
    "# And think of a filename to deposit our results in\n",
    "out_file = '/outputs/ridgecrest_twostations.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the P and S-wave velocities as inputs to estimate the inter-event distance. These are homogeneous velocities, but the velocity between events is not expected to vary very much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homogeneous velocity estimates for the Ridgecrest example\n",
    "Vp = 6000\n",
    "Vs = Vp/1.8\n",
    "\n",
    "# Stations: pick one or preferably two stations out of your station list. In this case\n",
    "# we only have two stations, so that is easy\n",
    "stations = ['WBS', 'WMF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WBS', 'WMF']\n",
      "{'WBS': [-58075.507727615535, -18408.043043394107, 0.0], 'WMF': [-31629.50772728643, 45782.95695989812, 0.0]}\n"
     ]
    }
   ],
   "source": [
    "# Create an input object with data loaded \n",
    "\n",
    "hobj = hades_input(\n",
    "    data_path = data_path,          # the general path to the data\n",
    "    event_file = input_file,        # the input event file path\n",
    "    station_file = station_file,    # the station file path\n",
    "    sta_select = stations           # your two stations\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now comes an important choice. \n",
    "\n",
    ">Depending on how many locations you have already and the quality/uncertainty on those locations, you can choose whether you want to use either:\n",
    "\n",
    "- One master event: HADES finds the events relative to one another on basis of a pre-defined estimated aperture between the master event and thee other chosen events. And then locates absolutely on basis of this master event. It then rotates the cluster on basis of the measured (ts-tp)\n",
    "- Four master events: HADES constructs a coordinate system on basis of these four events, does not need to rotate, and finds the absolute location relative to these four absolutelly located master events.\n",
    "- .>4 master events: same story, absolute cluster and cluster shape are constrained by the amount of master events. If your master events are very uncertain, maybe not the best way to go because you could introduce a lot of bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('obspy')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "919706ca7f2637aff2ebb36e84a087b50594c4fadb29ca76f5df1eb8ab927b14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
